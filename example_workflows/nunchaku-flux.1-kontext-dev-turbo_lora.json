{
  "id": "01ecd06d-0e30-419c-91d1-748e7d611cf0",
  "revision": 0,
  "last_node_id": 26,
  "last_link_id": 20,
  "nodes": [
    {
      "id": 1,
      "type": "VAELoader",
      "pos": [
        527.7552490234375,
        413.0078430175781
      ],
      "size": [
        337.76861572265625,
        58
      ],
      "flags": {},
      "order": 0,
      "mode": 0,
      "inputs": [],
      "outputs": [
        {
          "name": "VAE",
          "type": "VAE",
          "links": [
            5,
            7
          ]
        }
      ],
      "properties": {
        "cnr_id": "comfy-core",
        "ver": "0.3.38",
        "Node name for S&R": "VAELoader",
        "models": [
          {
            "name": "ae.safetensors",
            "url": "https://huggingface.co/Comfy-Org/Lumina_Image_2.0_Repackaged/resolve/main/split_files/vae/ae.safetensors",
            "directory": "vae"
          }
        ]
      },
      "widgets_values": [
        "ae.safetensors"
      ],
      "color": "#322",
      "bgcolor": "#533"
    },
    {
      "id": 2,
      "type": "DualCLIPLoader",
      "pos": [
        527.7552490234375,
        233.0077362060547
      ],
      "size": [
        337.76861572265625,
        130
      ],
      "flags": {},
      "order": 1,
      "mode": 0,
      "inputs": [],
      "outputs": [
        {
          "name": "CLIP",
          "type": "CLIP",
          "links": [
            18
          ]
        }
      ],
      "properties": {
        "cnr_id": "comfy-core",
        "ver": "0.3.38",
        "Node name for S&R": "DualCLIPLoader",
        "models": [
          {
            "name": "clip_l.safetensors",
            "url": "https://huggingface.co/comfyanonymous/flux_text_encoders/resolve/main/clip_l.safetensors",
            "directory": "text_encoders"
          },
          {
            "name": "t5xxl_fp8_e4m3fn_scaled.safetensors",
            "url": "https://huggingface.co/comfyanonymous/flux_text_encoders/resolve/main/t5xxl_fp8_e4m3fn_scaled.safetensors",
            "directory": "text_encoders"
          }
        ]
      },
      "widgets_values": [
        "clip_l.safetensors",
        "t5xxl_fp8_e4m3fn_scaled.safetensors",
        "flux",
        "default"
      ],
      "color": "#322",
      "bgcolor": "#533"
    },
    {
      "id": 3,
      "type": "ConditioningZeroOut",
      "pos": [
        1175.2686767578125,
        229.18930053710938
      ],
      "size": [
        240,
        26
      ],
      "flags": {
        "collapsed": false
      },
      "order": 17,
      "mode": 0,
      "inputs": [
        {
          "name": "conditioning",
          "type": "CONDITIONING",
          "link": 1
        }
      ],
      "outputs": [
        {
          "name": "CONDITIONING",
          "type": "CONDITIONING",
          "links": [
            16
          ]
        }
      ],
      "properties": {
        "cnr_id": "comfy-core",
        "ver": "0.3.39",
        "Node name for S&R": "ConditioningZeroOut"
      }
    },
    {
      "id": 4,
      "type": "PreviewImage",
      "pos": [
        1245.2686767578125,
        889.1893310546875
      ],
      "size": [
        420,
        310
      ],
      "flags": {},
      "order": 19,
      "mode": 0,
      "inputs": [
        {
          "name": "images",
          "type": "IMAGE",
          "link": 2
        }
      ],
      "outputs": [],
      "properties": {
        "cnr_id": "comfy-core",
        "ver": "0.3.40",
        "Node name for S&R": "PreviewImage"
      },
      "widgets_values": []
    },
    {
      "id": 5,
      "type": "SaveImage",
      "pos": [
        1685.2686767578125,
        539.1893310546875
      ],
      "size": [
        650,
        660
      ],
      "flags": {},
      "order": 25,
      "mode": 0,
      "inputs": [
        {
          "name": "images",
          "type": "IMAGE",
          "link": 3
        }
      ],
      "outputs": [],
      "properties": {
        "cnr_id": "comfy-core",
        "ver": "0.3.39"
      },
      "widgets_values": [
        "ComfyUI"
      ]
    },
    {
      "id": 6,
      "type": "LoadImageOutput",
      "pos": [
        875.2686157226562,
        799.1893310546875
      ],
      "size": [
        320,
        374
      ],
      "flags": {},
      "order": 2,
      "mode": 4,
      "inputs": [],
      "outputs": [
        {
          "name": "IMAGE",
          "type": "IMAGE",
          "links": [
            10
          ]
        },
        {
          "name": "MASK",
          "type": "MASK",
          "links": null
        }
      ],
      "properties": {
        "cnr_id": "comfy-core",
        "ver": "0.3.40",
        "Node name for S&R": "LoadImageOutput"
      },
      "widgets_values": [
        "WechatIMG4530.jpg [output]",
        false,
        "refresh",
        "image"
      ],
      "color": "#322",
      "bgcolor": "#533"
    },
    {
      "id": 7,
      "type": "VAEDecode",
      "pos": [
        1455.2686767578125,
        379.1893005371094
      ],
      "size": [
        190,
        46
      ],
      "flags": {
        "collapsed": false
      },
      "order": 24,
      "mode": 0,
      "inputs": [
        {
          "name": "samples",
          "type": "LATENT",
          "link": 4
        },
        {
          "name": "vae",
          "type": "VAE",
          "link": 5
        }
      ],
      "outputs": [
        {
          "name": "IMAGE",
          "type": "IMAGE",
          "slot_index": 0,
          "links": [
            3
          ]
        }
      ],
      "properties": {
        "cnr_id": "comfy-core",
        "ver": "0.3.38",
        "Node name for S&R": "VAEDecode"
      }
    },
    {
      "id": 8,
      "type": "VAEEncode",
      "pos": [
        905.2686157226562,
        429.1893005371094
      ],
      "size": [
        240,
        50
      ],
      "flags": {
        "collapsed": false
      },
      "order": 20,
      "mode": 0,
      "inputs": [
        {
          "name": "pixels",
          "type": "IMAGE",
          "link": 6
        },
        {
          "name": "vae",
          "type": "VAE",
          "link": 7
        }
      ],
      "outputs": [
        {
          "name": "LATENT",
          "type": "LATENT",
          "links": [
            13,
            17
          ]
        }
      ],
      "properties": {
        "cnr_id": "comfy-core",
        "ver": "0.3.39",
        "Node name for S&R": "VAEEncode"
      }
    },
    {
      "id": 9,
      "type": "FluxKontextImageScale",
      "pos": [
        875.2686157226562,
        599.1893310546875
      ],
      "size": [
        270,
        30
      ],
      "flags": {
        "collapsed": false
      },
      "order": 18,
      "mode": 0,
      "inputs": [
        {
          "name": "image",
          "type": "IMAGE",
          "link": 8
        }
      ],
      "outputs": [
        {
          "name": "IMAGE",
          "type": "IMAGE",
          "links": [
            2,
            6
          ]
        }
      ],
      "properties": {
        "cnr_id": "comfy-core",
        "ver": "0.3.38",
        "Node name for S&R": "FluxKontextImageScale"
      }
    },
    {
      "id": 10,
      "type": "MarkdownNote",
      "pos": [
        875.2686157226562,
        669.1893310546875
      ],
      "size": [
        320,
        88
      ],
      "flags": {},
      "order": 3,
      "mode": 0,
      "inputs": [],
      "outputs": [],
      "title": "About Flux Kontext Edit",
      "properties": {},
      "widgets_values": [
        "[English] Use Ctrl + B to enable multipule image input.\n\n[ä¸­æ–‡] ä½¿ç”¨ **Ctrl + B** æ¥å¯ç”¨å¤šå¼ å›¾ç‰‡è¾“å…¥"
      ],
      "color": "#432",
      "bgcolor": "#653"
    },
    {
      "id": 11,
      "type": "ImageStitch",
      "pos": [
        535.2686157226562,
        599.1893310546875
      ],
      "size": [
        270,
        150
      ],
      "flags": {},
      "order": 16,
      "mode": 0,
      "inputs": [
        {
          "name": "image1",
          "type": "IMAGE",
          "link": 9
        },
        {
          "name": "image2",
          "shape": 7,
          "type": "IMAGE",
          "link": 10
        }
      ],
      "outputs": [
        {
          "name": "IMAGE",
          "type": "IMAGE",
          "links": [
            8
          ]
        }
      ],
      "properties": {
        "cnr_id": "comfy-core",
        "ver": "0.3.40",
        "Node name for S&R": "ImageStitch"
      },
      "widgets_values": [
        "right",
        true,
        0,
        "white"
      ]
    },
    {
      "id": 12,
      "type": "FluxGuidance",
      "pos": [
        1175.2686767578125,
        119.1893081665039
      ],
      "size": [
        240,
        58
      ],
      "flags": {
        "collapsed": false
      },
      "order": 22,
      "mode": 0,
      "inputs": [
        {
          "name": "conditioning",
          "type": "CONDITIONING",
          "link": 11
        }
      ],
      "outputs": [
        {
          "name": "CONDITIONING",
          "type": "CONDITIONING",
          "slot_index": 0,
          "links": [
            15
          ]
        }
      ],
      "properties": {
        "cnr_id": "comfy-core",
        "ver": "0.3.38",
        "Node name for S&R": "FluxGuidance"
      },
      "widgets_values": [
        2.5
      ]
    },
    {
      "id": 13,
      "type": "MarkdownNote",
      "pos": [
        -34.73136520385742,
        519.1893310546875
      ],
      "size": [
        510,
        170
      ],
      "flags": {},
      "order": 4,
      "mode": 0,
      "inputs": [],
      "outputs": [],
      "title": "About VRAM",
      "properties": {},
      "widgets_values": [
        "For reference:\n- **fp8_scaled**: Requires about 20GB of VRAM.\n- **Original**: Requires about 32GB of VRAM.\n\n---\n\nä¾›å‚è€ƒï¼š\n-  **fp8_scaled** :  å¤§æ¦‚éœ€è¦ 20GB å·¦å³ VRAM \n- **åŸå§‹æƒé‡**:  åŸå§‹æƒé‡ï¼Œå¤§æ¦‚éœ€è¦ 32GB å·¦å³ VRAM \n"
      ],
      "color": "#432",
      "bgcolor": "#653"
    },
    {
      "id": 14,
      "type": "MarkdownNote",
      "pos": [
        -34.73136520385742,
        739.1893310546875
      ],
      "size": [
        510,
        170
      ],
      "flags": {},
      "order": 5,
      "mode": 0,
      "inputs": [],
      "outputs": [],
      "title": "Flux Kontext Prompt Techniques",
      "properties": {},
      "widgets_values": [
        "\n## Flux Kontext Prompt Techniques\n\n### 1. Basic Modifications\n- Simple and direct: `\"Change the car color to red\"`\n- Maintain style: `\"Change to daytime while maintaining the same style of the painting\"`\n\n### 2. Style Transfer\n**Principles:**\n- Clearly name style: `\"Transform to Bauhaus art style\"`\n- Describe characteristics: `\"Transform to oil painting with visible brushstrokes, thick paint texture\"`\n- Preserve composition: `\"Change to Bauhaus style while maintaining the original composition\"`\n\n### 3. Character Consistency\n**Framework:**\n- Specific description: `\"The woman with short black hair\"` instead of \"she\"\n- Preserve features: `\"while maintaining the same facial features, hairstyle, and expression\"`\n- Step-by-step modifications: Change background first, then actions\n\n### 4. Text Editing\n- Use quotes: `\"Replace 'joy' with 'BFL'\"`\n- Maintain format: `\"Replace text while maintaining the same font style\"`\n\n## Common Problem Solutions\n\n### Character Changes Too Much\nâŒ Wrong: `\"Transform the person into a Viking\"`\nâœ… Correct: `\"Change the clothes to be a viking warrior while preserving facial features\"`\n\n### Composition Position Changes\nâŒ Wrong: `\"Put him on a beach\"`\nâœ… Correct: `\"Change the background to a beach while keeping the person in the exact same position, scale, and pose\"`\n\n### Style Application Inaccuracy\nâŒ Wrong: `\"Make it a sketch\"`\nâœ… Correct: `\"Convert to pencil sketch with natural graphite lines, cross-hatching, and visible paper texture\"`\n\n## Core Principles\n\n1. **Be Specific and Clear** - Use precise descriptions, avoid vague terms\n2. **Step-by-step Editing** - Break complex modifications into multiple simple steps\n3. **Explicit Preservation** - State what should remain unchanged\n4. **Verb Selection** - Use \"change\", \"replace\" rather than \"transform\"\n\n## Best Practice Templates\n\n**Object Modification:**\n`\"Change [object] to [new state], keep [content to preserve] unchanged\"`\n\n**Style Transfer:**\n`\"Transform to [specific style], while maintaining [composition/character/other] unchanged\"`\n\n**Background Replacement:**\n`\"Change the background to [new background], keep the subject in the exact same position and pose\"`\n\n**Text Editing:**\n`\"Replace '[original text]' with '[new text]', maintain the same font style\"`\n\n> **Remember:** The more specific, the better. Kontext excels at understanding detailed instructions and maintaining consistency. "
      ],
      "color": "#432",
      "bgcolor": "#653"
    },
    {
      "id": 15,
      "type": "MarkdownNote",
      "pos": [
        -34.73136520385742,
        959.1893310546875
      ],
      "size": [
        510,
        180
      ],
      "flags": {},
      "order": 6,
      "mode": 0,
      "inputs": [],
      "outputs": [],
      "title": "Flux Kontext æç¤ºè¯æŠ€å·§",
      "properties": {},
      "widgets_values": [
        "\n## Flux Kontext æç¤ºè¯æŠ€å·§\n\nä½¿ç”¨è‹±æ–‡\n\n### 1. åŸºç¡€ä¿®æ”¹\n- ç®€å•ç›´æ¥ï¼š`\"Change the car color to red\"`\n- ä¿æŒé£æ ¼ï¼š`\"Change to daytime while maintaining the same style of the painting\"`\n\n### 2. é£æ ¼è½¬æ¢\n**åŸåˆ™ï¼š**\n- æ˜ç¡®å‘½åé£æ ¼ï¼š`\"Transform to Bauhaus art style\"`\n- æè¿°ç‰¹å¾ï¼š`\"Transform to oil painting with visible brushstrokes, thick paint texture\"`\n- ä¿ç•™æ„å›¾ï¼š`\"Change to Bauhaus style while maintaining the original composition\"`\n\n### 3. è§’è‰²ä¸€è‡´æ€§\n**æ¡†æ¶ï¼š**\n- å…·ä½“æè¿°ï¼š`\"The woman with short black hair\"`è€Œé`\"å¥¹\"`\n- ä¿ç•™ç‰¹å¾ï¼š`\"while maintaining the same facial features, hairstyle, and expression\"`\n- åˆ†æ­¥ä¿®æ”¹ï¼šå…ˆæ”¹èƒŒæ™¯ï¼Œå†æ”¹åŠ¨ä½œ\n\n### 4. æ–‡æœ¬ç¼–è¾‘\n- ä½¿ç”¨å¼•å·ï¼š`\"Replace 'joy' with 'BFL'\"`\n- ä¿æŒæ ¼å¼ï¼š`\"Replace text while maintaining the same font style\"`\n\n## å¸¸è§é—®é¢˜è§£å†³\n\n### è§’è‰²å˜åŒ–è¿‡å¤§\nâŒ é”™è¯¯ï¼š`\"Transform the person into a Viking\"`\nâœ… æ­£ç¡®ï¼š`\"Change the clothes to be a viking warrior while preserving facial features\"`\n\n### æ„å›¾ä½ç½®æ”¹å˜\nâŒ é”™è¯¯ï¼š`\"Put him on a beach\"`\nâœ… æ­£ç¡®ï¼š`\"Change the background to a beach while keeping the person in the exact same position, scale, and pose\"`\n\n### é£æ ¼åº”ç”¨ä¸å‡†ç¡®\nâŒ é”™è¯¯ï¼š`\"Make it a sketch\"`\nâœ… æ­£ç¡®ï¼š`\"Convert to pencil sketch with natural graphite lines, cross-hatching, and visible paper texture\"`\n\n## æ ¸å¿ƒåŸåˆ™\n\n1. **å…·ä½“æ˜ç¡®** - ä½¿ç”¨ç²¾ç¡®æè¿°ï¼Œé¿å…æ¨¡ç³Šè¯æ±‡\n2. **åˆ†æ­¥ç¼–è¾‘** - å¤æ‚ä¿®æ”¹åˆ†ä¸ºå¤šä¸ªç®€å•æ­¥éª¤\n3. **æ˜ç¡®ä¿ç•™** - è¯´æ˜å“ªäº›è¦ä¿æŒä¸å˜\n4. **åŠ¨è¯é€‰æ‹©** - ç”¨\"æ›´æ”¹\"ã€\"æ›¿æ¢\"è€Œé\"è½¬æ¢\"\n\n## æœ€ä½³å®è·µæ¨¡æ¿\n\n**å¯¹è±¡ä¿®æ”¹ï¼š**\n`\"Change [object] to [new state], keep [content to preserve] unchanged\"`\n\n**é£æ ¼è½¬æ¢ï¼š**\n`\"Transform to [specific style], while maintaining [composition/character/other] unchanged\"`\n\n**èƒŒæ™¯æ›¿æ¢ï¼š**\n`\"Change the background to [new background], keep the subject in the exact same position and pose\"`\n\n**æ–‡æœ¬ç¼–è¾‘ï¼š**\n`\"Replace '[original text]' with '[new text]', maintain the same font style\"`\n\n> **è®°ä½ï¼š** è¶Šå…·ä½“è¶Šå¥½ï¼ŒKontext æ“…é•¿ç†è§£è¯¦ç»†æŒ‡ä»¤å¹¶ä¿æŒä¸€è‡´æ€§ã€‚"
      ],
      "color": "#432",
      "bgcolor": "#653"
    },
    {
      "id": 16,
      "type": "MarkdownNote",
      "pos": [
        -34.73136520385742,
        69.1893081665039
      ],
      "size": [
        510,
        400
      ],
      "flags": {},
      "order": 7,
      "mode": 0,
      "inputs": [],
      "outputs": [],
      "title": "Model links",
      "properties": {},
      "widgets_values": [
        "[tutorial](http://docs.comfy.org/tutorials/flux/flux-1-kontext-dev) | [æ•™ç¨‹](http://docs.comfy.org/zh-CN/tutorials/flux/flux-1-kontext-dev)\n\n**diffusion model**\n\n- [flux1-dev-kontext_fp8_scaled.safetensors](https://huggingface.co/Comfy-Org/flux1-kontext-dev_ComfyUI/resolve/main/split_files/diffusion_models/flux1-dev-kontext_fp8_scaled.safetensors)\n\n**vae**\n\n- [ae.safetensors](https://huggingface.co/Comfy-Org/Lumina_Image_2.0_Repackaged/blob/main/split_files/vae/ae.safetensors)\n\n**text encoder**\n\n- [clip_l.safetensors](https://huggingface.co/comfyanonymous/flux_text_encoders/blob/main/clip_l.safetensors)\n- [t5xxl_fp16.safetensors](https://huggingface.co/comfyanonymous/flux_text_encoders/resolve/main/t5xxl_fp16.safetensors) or [t5xxl_fp8_e4m3fn_scaled.safetensors](https://huggingface.co/comfyanonymous/flux_text_encoders/resolve/main/t5xxl_fp8_e4m3fn_scaled.safetensors)\n\nModel Storage Location\n\n```\nğŸ“‚ ComfyUI/\nâ”œâ”€â”€ ğŸ“‚ models/\nâ”‚   â”œâ”€â”€ ğŸ“‚ diffusion_models/\nâ”‚   â”‚   â””â”€â”€ flux1-dev-kontext_fp8_scaled.safetensors\nâ”‚   â”œâ”€â”€ ğŸ“‚ vae/\nâ”‚   â”‚   â””â”€â”€ ae.safetensor\nâ”‚   â””â”€â”€ ğŸ“‚ text_encoders/\nâ”‚       â”œâ”€â”€ clip_l.safetensors\nâ”‚       â””â”€â”€ t5xxl_fp16.safetensors æˆ–è€… t5xxl_fp8_e4m3fn_scaled.safetensors\n```\n"
      ],
      "color": "#432",
      "bgcolor": "#653"
    },
    {
      "id": 17,
      "type": "ReferenceLatent",
      "pos": [
        935.2686157226562,
        169.18930053710938
      ],
      "size": [
        197.712890625,
        46
      ],
      "flags": {},
      "order": 21,
      "mode": 0,
      "inputs": [
        {
          "name": "conditioning",
          "type": "CONDITIONING",
          "link": 12
        },
        {
          "name": "latent",
          "shape": 7,
          "type": "LATENT",
          "link": 13
        }
      ],
      "outputs": [
        {
          "name": "CONDITIONING",
          "type": "CONDITIONING",
          "links": [
            11
          ]
        }
      ],
      "properties": {
        "cnr_id": "comfy-core",
        "ver": "0.3.41",
        "Node name for S&R": "ReferenceLatent"
      }
    },
    {
      "id": 18,
      "type": "MarkdownNote",
      "pos": [
        895.2686157226562,
        -120.8106918334961
      ],
      "size": [
        540,
        150
      ],
      "flags": {},
      "order": 8,
      "mode": 0,
      "inputs": [],
      "outputs": [],
      "title": "About multiple images reference",
      "properties": {},
      "widgets_values": [
        "[English] In addition to using **Image Stitch** to combine two images at a time, you can also encode individual images, then concatenate multiple latent conditions using the **ReferenceLatent** node, thus achieving the purpose of referencing multiple images. You can use the **EmptySD3LatentImage** node on the right to connect to **KSamper** and customize the size of the **latent_image**.\n\n[ä¸­æ–‡] é™¤äº†ä½¿ç”¨ **Image Stitch** å°†ä¸¤ä¸ªä¸¤ä¸ªå›¾åƒæ‹¼åˆä¹‹å¤–ï¼Œä½ åŒæ ·å¯ä»¥å°†å•ç‹¬çš„å›¾åƒ encode ä¹‹åï¼Œå°†å¤šä¸ª latent æ¡ä»¶ä½¿ç”¨ **ReferenceLatent** èŠ‚ç‚¹ä¸²è”ï¼Œä»è€Œå®ç°å¤šå¼ å›¾åƒå‚è€ƒçš„ç›®çš„ã€‚å¯ä»¥ä½¿ç”¨å³è¾¹çš„ **EmptySD3LatentImage** èŠ‚ç‚¹è¿æ¥åˆ° **KSamper**æ¥è‡ªå®šä¹‰ **latent_image** çš„å°ºå¯¸"
      ],
      "color": "#432",
      "bgcolor": "#653"
    },
    {
      "id": 19,
      "type": "EmptySD3LatentImage",
      "pos": [
        1455.2686767578125,
        -110.8106918334961
      ],
      "size": [
        310,
        106
      ],
      "flags": {},
      "order": 9,
      "mode": 4,
      "inputs": [],
      "outputs": [
        {
          "name": "LATENT",
          "type": "LATENT",
          "links": null
        }
      ],
      "properties": {
        "cnr_id": "comfy-core",
        "ver": "0.3.41",
        "Node name for S&R": "EmptySD3LatentImage"
      },
      "widgets_values": [
        1024,
        1024,
        1
      ]
    },
    {
      "id": 21,
      "type": "MarkdownNote",
      "pos": [
        -504.7313537597656,
        69.1893081665039
      ],
      "size": [
        450,
        450
      ],
      "flags": {},
      "order": 10,
      "mode": 0,
      "inputs": [],
      "outputs": [],
      "title": "âœ¨ New ComfyUI feature for Flux.1 Kontext Dev",
      "properties": {},
      "widgets_values": [
        "[English]\nWe have added an **Edit** button to the **Selection Toolbox** of the node for **FLUX.1 Kontext Image Edit** support. When clicked, it quickly adds a **FLUX.1 Kontext Image Edit** group node to the Latent output of your current workflow. This enables an interactive editing experience where you can:\n\n- Create multiple editing iterations, each preserved as a separate node\n- Easily branch off from any previous edit point to explore different creative directions\n- Return to any earlier version and start a new editing branch\n- Modify parameters in earlier nodes and automatically update all downstream edits\n- Execute or re-execute any branch of edits at any time\n- When you want to maintain the effect of the corresponding branch, please set the seed of the corresponding group node to fixed.\n\n\nThis workflow mirrors the iterative nature of LLM conversations, but with the added advantage of visual editing and the ability to maintain multiple parallel editing paths.\n\n---\n\n[ä¸­æ–‡]\næˆ‘ä»¬ä¸º **FLUX.1 Kontext Image Edit** çš„ç›¸å…³æ”¯æŒåœ¨èŠ‚ç‚¹çš„**é€‰æ‹©å·¥å…·ç®±**ä¸Šæ–°å¢äº†ä¸€ä¸ª**ç¼–è¾‘**æŒ‰é’®ã€‚ç‚¹å‡»åï¼Œç³»ç»Ÿä¼šåœ¨å½“å‰å·¥ä½œæµçš„ Latent è¾“å‡ºä¸Šå¿«é€Ÿæ·»åŠ ä¸€ä¸ª **FLUX.1 Kontext Image Edit** çš„ç»„èŠ‚ç‚¹ã€‚è¿™ç§è®¾è®¡å¸¦æ¥äº†çµæ´»çš„äº¤äº’å¼ç¼–è¾‘ä½“éªŒï¼š\n\n- åˆ›å»ºå¤šä¸ªç¼–è¾‘è¿­ä»£ï¼Œæ¯æ¬¡ç¼–è¾‘éƒ½ä¼šä¿å­˜ä¸ºç‹¬ç«‹èŠ‚ç‚¹\n- å¯ä»¥ä»ä»»ä½•ä¹‹å‰çš„ç¼–è¾‘ç‚¹åˆ†æ”¯å‡ºæ–°çš„åˆ›ä½œæ–¹å‘\n- éšæ—¶è¿”å›åˆ°æ—©æœŸç‰ˆæœ¬å¹¶å¼€å§‹æ–°çš„ç¼–è¾‘åˆ†æ”¯\n- ä¿®æ”¹æ—©æœŸèŠ‚ç‚¹çš„å‚æ•°ï¼Œè‡ªåŠ¨æ›´æ–°æ‰€æœ‰ä¸‹æ¸¸ç¼–è¾‘\n- å¯ä»¥éšæ—¶æ‰§è¡Œæˆ–é‡æ–°æ‰§è¡Œä»»ä½•ç¼–è¾‘åˆ†æ”¯\n- æƒ³è¦å›ºå®šå¯¹åº”åˆ†æ”¯æ•ˆæœæ—¶ï¼Œè¯·å°†å¯¹åº”çš„ seed è®¾ç½®ä¸º fixed\n\nè¿™ç§å·¥ä½œæµç¨‹ç±»ä¼¼äº LLM å¯¹è¯çš„è¿­ä»£ç‰¹æ€§ï¼Œä½†å¢åŠ äº†è§†è§‰ç¼–è¾‘çš„ä¼˜åŠ¿ï¼Œå¹¶èƒ½å¤Ÿç»´æŠ¤å¤šä¸ªå¹¶è¡Œçš„ç¼–è¾‘è·¯å¾„ã€‚"
      ],
      "color": "#322",
      "bgcolor": "#533"
    },
    {
      "id": 25,
      "type": "CLIPTextEncode",
      "pos": [
        1255.2686767578125,
        589.1893310546875
      ],
      "size": [
        400,
        220
      ],
      "flags": {},
      "order": 14,
      "mode": 0,
      "inputs": [
        {
          "name": "clip",
          "type": "CLIP",
          "link": 18
        }
      ],
      "outputs": [
        {
          "name": "CONDITIONING",
          "type": "CONDITIONING",
          "slot_index": 0,
          "links": [
            1,
            12
          ]
        }
      ],
      "title": "CLIP Text Encode (Positive Prompt)",
      "properties": {
        "cnr_id": "comfy-core",
        "ver": "0.3.38",
        "Node name for S&R": "CLIPTextEncode"
      },
      "widgets_values": [
        "Make Pikachu hold a sign that says 'Nunchaku is awesome', yarn art style, detailed, vibrant colors"
      ],
      "color": "#232",
      "bgcolor": "#353"
    },
    {
      "id": 22,
      "type": "NunchakuFluxDiTLoader",
      "pos": [
        558.5625,
        -142.81434631347656
      ],
      "size": [
        275.7613220214844,
        202
      ],
      "flags": {},
      "order": 11,
      "mode": 0,
      "inputs": [],
      "outputs": [
        {
          "name": "MODEL",
          "type": "MODEL",
          "links": [
            19
          ]
        }
      ],
      "properties": {
        "cnr_id": "ComfyUI-nunchaku",
        "ver": "3b2c771cf2f4e62f97c284bfd8f594482c5f8bc0",
        "Node name for S&R": "NunchakuFluxDiTLoader"
      },
      "widgets_values": [
        "svdq-int4_r32-flux.1-kontext-dev.safetensors",
        0,
        "nunchaku-fp16",
        "auto",
        0,
        "bfloat16",
        "enabled"
      ]
    },
    {
      "id": 26,
      "type": "NunchakuFluxLoraLoader",
      "pos": [
        545.2327880859375,
        114.53527069091797
      ],
      "size": [
        300.6851501464844,
        82
      ],
      "flags": {},
      "order": 15,
      "mode": 0,
      "inputs": [
        {
          "name": "model",
          "type": "MODEL",
          "link": 19
        }
      ],
      "outputs": [
        {
          "name": "MODEL",
          "type": "MODEL",
          "links": [
            20
          ]
        }
      ],
      "properties": {
        "cnr_id": "ComfyUI-nunchaku",
        "ver": "3b2c771cf2f4e62f97c284bfd8f594482c5f8bc0",
        "Node name for S&R": "NunchakuFluxLoraLoader"
      },
      "widgets_values": [
        "flux.1-turbo-alpha.safetensors",
        1
      ]
    },
    {
      "id": 20,
      "type": "KSampler",
      "pos": [
        1455.2686767578125,
        69.1893081665039
      ],
      "size": [
        320,
        262
      ],
      "flags": {},
      "order": 23,
      "mode": 0,
      "inputs": [
        {
          "name": "model",
          "type": "MODEL",
          "link": 20
        },
        {
          "name": "positive",
          "type": "CONDITIONING",
          "link": 15
        },
        {
          "name": "negative",
          "type": "CONDITIONING",
          "link": 16
        },
        {
          "name": "latent_image",
          "type": "LATENT",
          "link": 17
        }
      ],
      "outputs": [
        {
          "name": "LATENT",
          "type": "LATENT",
          "slot_index": 0,
          "links": [
            4
          ]
        }
      ],
      "properties": {
        "cnr_id": "comfy-core",
        "ver": "0.3.38",
        "Node name for S&R": "KSampler"
      },
      "widgets_values": [
        250965779323742,
        "randomize",
        8,
        1,
        "euler",
        "simple",
        1
      ]
    },
    {
      "id": 23,
      "type": "MarkdownNote",
      "pos": [
        139.17037963867188,
        -144.5917205810547
      ],
      "size": [
        390.7500915527344,
        159.8812713623047
      ],
      "flags": {},
      "order": 12,
      "mode": 0,
      "inputs": [],
      "outputs": [],
      "properties": {},
      "widgets_values": [
        "Download the model from [HuggingFace](https://huggingface.co/mit-han-lab/nunchaku-flux.1-kontext-dev) or [ModelScope](https://modelscope.cn/models/Lmxyy1999/nunchaku-flux.1-kontext-dev).\n\n- Use the **FP4** variant if you're running on **Blackwell (50-series) GPUs**.\n- Otherwise, choose the **INT4** version for better compatibility.\n\nYou can adjust the `cache_threshold` parameter to balance **image quality** and **inference speed**. A value of `0.12` typically offers a good trade-off.\n\nEnable `cpu_offload` to **save GPU memory** if you're running into memory limits.\n\nThe Turbo LoRA can be found at this [HuggingFace Repo](https://huggingface.co/alimama-creative/FLUX.1-Turbo-Alpha)."
      ],
      "color": "#432",
      "bgcolor": "#653"
    },
    {
      "id": 24,
      "type": "LoadImageOutput",
      "pos": [
        535.2686157226562,
        799.1893310546875
      ],
      "size": [
        320,
        374
      ],
      "flags": {},
      "order": 13,
      "mode": 0,
      "inputs": [],
      "outputs": [
        {
          "name": "IMAGE",
          "type": "IMAGE",
          "links": [
            9
          ]
        },
        {
          "name": "MASK",
          "type": "MASK",
          "links": null
        }
      ],
      "properties": {
        "cnr_id": "comfy-core",
        "ver": "0.3.40",
        "Node name for S&R": "LoadImageOutput"
      },
      "widgets_values": [
        "yarn-art-pikachu.png [output]",
        false,
        "refresh",
        "image"
      ],
      "color": "#322",
      "bgcolor": "#533"
    }
  ],
  "links": [
    [
      1,
      25,
      0,
      3,
      0,
      "CONDITIONING"
    ],
    [
      2,
      9,
      0,
      4,
      0,
      "IMAGE"
    ],
    [
      3,
      7,
      0,
      5,
      0,
      "IMAGE"
    ],
    [
      4,
      20,
      0,
      7,
      0,
      "LATENT"
    ],
    [
      5,
      1,
      0,
      7,
      1,
      "VAE"
    ],
    [
      6,
      9,
      0,
      8,
      0,
      "IMAGE"
    ],
    [
      7,
      1,
      0,
      8,
      1,
      "VAE"
    ],
    [
      8,
      11,
      0,
      9,
      0,
      "IMAGE"
    ],
    [
      9,
      24,
      0,
      11,
      0,
      "IMAGE"
    ],
    [
      10,
      6,
      0,
      11,
      1,
      "IMAGE"
    ],
    [
      11,
      17,
      0,
      12,
      0,
      "CONDITIONING"
    ],
    [
      12,
      25,
      0,
      17,
      0,
      "CONDITIONING"
    ],
    [
      13,
      8,
      0,
      17,
      1,
      "LATENT"
    ],
    [
      15,
      12,
      0,
      20,
      1,
      "CONDITIONING"
    ],
    [
      16,
      3,
      0,
      20,
      2,
      "CONDITIONING"
    ],
    [
      17,
      8,
      0,
      20,
      3,
      "LATENT"
    ],
    [
      18,
      2,
      0,
      25,
      0,
      "CLIP"
    ],
    [
      19,
      22,
      0,
      26,
      0,
      "MODEL"
    ],
    [
      20,
      26,
      0,
      20,
      0,
      "MODEL"
    ]
  ],
  "groups": [
    {
      "id": 1,
      "title": "Step 2 - Upload images",
      "bounding": [
        515.2686157226562,
        509.1893005371094,
        700,
        680
      ],
      "color": "#3f789e",
      "font_size": 24,
      "flags": {}
    },
    {
      "id": 2,
      "title": "Step 3 - Prompt",
      "bounding": [
        1235.2686767578125,
        509.1893005371094,
        430,
        330
      ],
      "color": "#3f789e",
      "font_size": 24,
      "flags": {}
    },
    {
      "id": 3,
      "title": "Conditioning",
      "bounding": [
        895.2686157226562,
        39.18930435180664,
        540,
        250
      ],
      "color": "#3f789e",
      "font_size": 24,
      "flags": {}
    }
  ],
  "config": {},
  "extra": {
    "ds": {
      "scale": 0.7400249944258639,
      "offset": [
        415.32938004324257,
        185.38596457319667
      ]
    },
    "frontendVersion": "1.23.4"
  },
  "version": 0.4
}
